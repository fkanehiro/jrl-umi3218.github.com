---
layout: default
title: CNRS-AIST JRL - Humanoid Lab (Univ. of Tsukuba)
---

<div class="breadcrumbs-container">
<div class="container">
  <div class="row">
    <div class="col-lg-12">
      <ol class="breadcrumb">
        <li><a href="/index_en.html">Home</a>
        </li><li class="active">Humanoid Lab</li></ol>
      <h1 class="page-header">Humanoid Lab<small>
	  <br/>
	  <a href="https://www.tsukuba.ac.jp/en/academics/g-courses-cooperative/" target="blank_">University of Tsukuba - Cooperative Graduate School System <span class="glyphicon glyphicon-globe" style="font-size: small;"></span></a></small></h1>
    </div>
  </div>
</div>
</div>


<!-- Page Content -->
<div class="container">

  <table width="840" border="0" align="center" cellspacing="0" cellpadding="20">
    <tbody>
      <tr><td>

      <table border="0" width="100%" cellpadding="7">
        <tbody>
          <tr>
            <td width="300">
	      <img src="{{site.baseurl}}/en/assets/members/nopicture.png" width="155" border="0" style="border-radius:15px">
	    </td>
            <td>
	      <p>
	      TODO: Brief Introduction of the Humanoid Lab (i.e. it is a lab under Prof. Kanehiro...) and the cooperative graduate school system.
	      </p>
	      <p>
	      TODO: The lab is always looking for talented graduate students... Contact information to join the lab.
	      </p>
	      <p>制御技術、複雑環境において周囲の環境の3次元計測を行って自己の状態を正確に推定し、計測結果から手や足をつける場所を認識する技術、
		多数の関節を持ち環境に固定されていないロボットを簡単な操作で遠隔操作したり新たな行動を教示したりする技術等の研究を行っています。
		研究室は産業技術総合研究所つくばセンター内にあり、HRP-2改を初めとした複数の等身大ヒューマノイドロボットを有し、
		このようなロボットを研究に使用することができる国内でも数少ない研究室の一つです。</p>

	      <p><b>Under Prof. Kanehiro, the lab provides a unique opportunity for graduate students to work with Japanese and foreign research scientists on a
		  variety of robot platforms. Our main research subjects include: task and motion planning and control, multimodal interaction
		  with human and surrounding environment through perception, and cognitive robotics. We host always more than ten foreign researchers,
		  which characterizes the international atmosphere of this research group.</b></p>

	      <p>Check out our YouTube channel <a href="https://www.youtube.com/channel/UCYwHCdMHAKYZJ2MQIoTavVQ"> here. </a></p>
	    </td>
	  </tr>
        </tbody>
      </table>

      <div class="row">
	<div class="col-lg-12">
	  <h3 class="page-header">Research Content</h3>
	  <!-- content -->
	  <table border="0" width="100%" cellpadding="17" cellspacing="0" bgcolor="#e0f0fe" >
            <tbody>
              <tr valign="top">
		<td>
		  <table border="0" width="100%" cellpadding="0" cellspacing="0" >
		    <tbody>
                      <tr>
			<td><b><font size="+1">Simultaneous localization and mapping(SLAM) in dynamic environment</font></b></td>
			<td>&nbsp;</td>
			<td rowspan="3" valign="top" width="200">&nbsp;<img src="{{site.baseurl}}/en/assets/humanoidlab/hl_01_slam.jpg" height="227" border="0"></td>
                      </tr>
                      <tr>
			<td height="10"></td>
			<td height="10"></td>
                      </tr>
                      <tr>
			<td valign="top">Nowadays, SLAM in the dynamic environment has become a popular topic.
			  This problem is called dynamic SLAM where many solutions have been proposed to segment
			  out the dynamic objects that bring errors to camera tracking and subsequent 3D reconstruction.
			  However, state-of-the-art dynamic SLAM methods face the problems of accuracy and speed, which
			  is due to the fact that one segmentation algorithm cannot guarantee both points at the same time.
			  We propose a multi-purpose dynamic SLAM framework to provide a variety of selections for segmentation,
			  each has its applicable scene. Besides, if the user selects the semantic segmentation, the object-oriented
			  semantic mapping is beneficial for high level robotic tasks. </td>
			<td width="50">&nbsp;</td>
                      </tr>
		    </tbody>
		  </table>
		</td>
              </tr>
            </tbody>
	  </table>

	  <br>
	  <br>

	  <!-- content -->
	  <table border="0" width="100%" cellpadding="17" cellspacing="0" bgcolor="#e0f0fe">
            <tbody>
              <tr valign="top">
		<td>
		  <table border="0" width="100%" cellpadding="0" cellspacing="0">
		    <tbody>
                      <tr>
			<td><b><font size="+1">6-DoF Object Pose Estimation</font></b></td>
			<td>&nbsp;</td>
			<td rowspan="3" width="312"><img src="{{site.baseurl}}/en/assets/humanoidlab/hl_02.png" width="311" border="0"></td>
                      </tr>
                      <tr>
			<td height="10"></td>
			<td height="10"></td>
                      </tr>
                      <tr>
			<td valign="top">For a humanoid robot to interact with objects in its surrounding environment,
			  it is essential for the robot to find the position and orientation of the object relative to
			  itself - often through the use of its vision sensors. The 3D position and roll, pitch, yaw
			  rotation together comprise the 6 degrees-of-freedom pose of the object. For precise grasping
			  and manipulation of tools, this pose needs to be estimated with a  high degree of accuracy.
			  Further, we desire robustness against challenging lighting conditions, occlusions, and non-availability
			  of dense and accurate object models. This work mainly involves the use of Deep Learning based strategies
			  for solving problems in this sphere.
			</td>
			<td width="50">&nbsp;</td>
                      </tr>
		    </tbody>
		  </table>
		</td>
              </tr>
            </tbody>
	  </table>
	</div>
      </div>

      <div class="row">
	<div class="col-lg-12">
	  <h3 class="page-header">Student Members</h3>
          <table width="100%" border="0" cellspacing="0" class="table table-striped">
            <tbody>
              <tr>
		<th width="25%">氏名</th>
		<th width="25%">役職/学年</th>
		<th width="25%">メールアドレス <br>
		  _*_を@に変えて送信ください</th>
              </tr>
	      <!--
		  <tr>
		    <td><a href="https://unit.aist.go.jp/jrl-22022/en/members/member-kanehiro.html">金広 文男</a></td>
		    <td>連携大学院教授</td>
		    <td width="25%">f-kanehiro_*_aist.go.jp</td>
		  </tr>
		  -->
			  <tr>
		<td><a href="https://unit.aist.go.jp/jrl-22022/en/members/member-qin.html">覃 毅力</a></td>
		<td>博士課程4年</td>
		<td width="25%">yili.tan_*_aist.go.jp</td>
              </tr>
              <tr>
		<td><a href="https://unit.aist.go.jp/jrl-22022/en/members/member-sun.html">孫 楽源</a></td>
		<td>博士課程3年</td>
		<td width="25%">son.leyuansun_*_aist.go.jp</td>
              </tr>
              <tr>
		<td><a href="https://unit.aist.go.jp/jrl-22022/en/members/member-singh.html">Rohan Pratap Singh</a></td>
		<td>博士課程2年</td>
		<td width="25%">rohan-singh_*_aist.go.jp</td>
              </tr>
              <tr>
		<td>Xinchi Gao</td>
		<td>修士課程1年</td>
		<td width="25%"></td>
              </tr>
              <tr>
		<td>屋宮 友哉</td>
		<td>修士課程1年</td>
		<td width="25%"></td>
              </tr>
            </tbody>
          </table>
	</div>
      </div>

      </td></tr>
    <tbody>
  </table>
</div>
<!-- /.container -->

